1
Aim - Design a Lexical analyzer for identifying different types of token used in C 
language. 
Theory - 
A Lexical Analyzer (also known as a Lexer) is a program that reads source code 
and converts it into tokens. In the case of the C language, tokens include keywords, 
identifiers, operators, literals, and punctuation symbols. 
Steps to Design a Lexical Analyzer 
1. Read input source code character by character. 
2. Identify and classify tokens (keywords, identifiers, numbers, operators, etc.). 
3. Ignore whitespace and comments. 
4. Return tokens to the parser. 
Code -  
#include <stdio.h> 
#include <ctype.h> 
#include <string.h> 
#define MAX_TOKEN_LENGTH 100 
// Token types 
typedef enum {  
KEYWORD, IDENTIFIER, NUMBER, OPERATOR, DELIMITER, 
STRING_LITERAL, CHAR_LITERAL, COMMENT, WHITESPACE, 
UNKNOWN 
} TokenType; 
const char *token_type_names[] = { 
"KEYWORD", "IDENTIFIER", "NUMBER", "OPERATOR", "DELIMITER", 
"STRING_LITERAL", "CHAR_LITERAL", "COMMENT", "WHITESPACE", 
"UNKNOWN" 
}; 
// Keywords list 
const char *keywords[] = { 
"auto", "break", "case", "char", "const", "continue", "default", "do", "double", 
"else", "enum", "extern", "float", "for", "goto", "if", "inline", "int", "long", 
"register", "restrict", "return", "short", "signed", "sizeof", "static", "struct", 
"switch", "typedef", "union", "unsigned", "void", "volatile", "while", NULL 
}; 
// Function to check if a word is a keyword 
int is_keyword(const char *word) { 
for (int i = 0; keywords[i] != NULL; i++) { 
if (strcmp(word, keywords[i]) == 0) { 
return 1; 
} 
} 
return 0; 
} 
// Function to get token type 
TokenType get_token_type(const char *token) { 
if (is_keyword(token)) return KEYWORD; 
if (isdigit(token[0])) return NUMBER; 
if (isalpha(token[0]) || token[0] == '_') return IDENTIFIER; 
if (strchr("+-*/%=!><|&^~", token[0])) return OPERATOR; 
if (strchr("(),;{}[]", token[0])) return DELIMITER; 
if (token[0] == '"') return STRING_LITERAL; 
if (token[0] == '\'') return CHAR_LITERAL; 
return UNKNOWN; 
} 
// Lexical Analyzer function 
void lexical_analyzer(const char *code) { 
char token[MAX_TOKEN_LENGTH]; 
int i = 0, j = 0; 
while (code[i] != '\0') { 
if (isspace(code[i])) { 
i++; 
continue; 
} 
if (isalnum(code[i]) || code[i] == '_') { 
j = 0; 
while (isalnum(code[i]) || code[i] == '_') { 
token[j++] = code[i++]; 
} 
token[j] = '\0'; 
TokenType type = get_token_type(token); 
printf("Token: %s, Type: %s\n", token, token_type_names[type]); 
} else { 
TokenType type = get_token_type((char[]){code[i], '\0'}); 
printf("Token: %c, Type: %s\n", code[i], token_type_names[type]); 
i++; 
} 
} 
} 
int main() { 
const char *c_code = "int main() { int x = 10; float y = 5.5; printf(\"Hello, 
World!\"); return 0; }"; 
lexical_analyzer(c_code); 
return 0; 
}
